{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import qmc\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF, Matern, RationalQuadratic, Kernel, Hyperparameter\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "\n",
    "import GPy\n",
    "import gpytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CategoryOverlapKernelGPy(GPy.kern.Kern):\n",
    "    \"\"\"GPy implementation of a categorical overlap kernel.\"\"\"\n",
    "\n",
    "    def __init__(self, input_dim, variance=1.0, active_dims=None, name='catoverlap'):\n",
    "        super().__init__(input_dim, active_dims=active_dims, name=name)\n",
    "        self.variance = GPy.core.parameterization.Param('variance', variance)\n",
    "        self.link_parameter(self.variance)\n",
    "\n",
    "    def K(self, X, X2=None):\n",
    "        if X2 is None:\n",
    "            X2 = X\n",
    "\n",
    "        diff = X[:, None] - X2[None, :]\n",
    "        diff[np.where(np.abs(diff))] = 1  # Mark different categories\n",
    "        k_cat = self.variance * (1 - np.mean(diff, axis=-1))  # Normalize overlap\n",
    "        return k_cat\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPy Kernel Matrix:\n",
      " [[1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 1. 0. 0. 0.]\n",
      " [0. 1. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "X_test = np.array([[4], [2], [2], [1], [0], [8]]) #each row is a category\n",
    "\n",
    "# Create kernel and compute the kernel matrix\n",
    "gpy_kernel = CategoryOverlapKernelGPy(input_dim=1, variance=1.0)\n",
    "K_gpy = gpy_kernel.K(X_test)\n",
    "print(\"GPy Kernel Matrix:\\n\", K_gpy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import gpytorch\n",
    "\n",
    "class CategoryOverlapKernel(gpytorch.kernels.Kernel):\n",
    "    \"\"\"Custom kernel for cateogrical varaibles using category overlap similarity.\"\"\"\n",
    "    \n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(has_lengthsacle = False, **kwargs)\n",
    "    \n",
    "    def forward(self, x1, x2, diag = False, **params):\n",
    "        if diag:\n",
    "            return torch.ones(x1.shape[0], dtype=x1.dtype, device=x1.device)\n",
    "        \n",
    "        #check if categorical values are teh same (Kronecker delta function)\n",
    "        overlap = x1[:, None] == x2[None, :].float()\n",
    "        return overlap\n",
    "    \n",
    "    \n",
    "class CombinedKernel(gpytorch.kernels.Kernel):\n",
    "    \"\"\"Combined Matern kernel and Category Overlap Kernel\"\"\"\n",
    "\n",
    "    def __init__(self, matern_nu=2.5, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.matern_kernel = gpytorch.kernels.MaternKernel(nu=matern_nu)\n",
    "        self.category_kernel = CategoryOverlapKernel()\n",
    "\n",
    "    def forward(self, x1, x2, diag = False, **params):\n",
    "        #split cont and cat features\n",
    "        x1_cont, x1_cat = x1[..., :-1], x1[..., -1]\n",
    "        x2_cont, x2_cat = x2[..., :-1], x2[..., -1]\n",
    "\n",
    "        # computer kernel values\n",
    "        matern_val = self.matern_kernel(x1_cont, x2_cont, diag=diag, **params)\n",
    "        category_val = self.category_kernel(x1_cat, x2_cat, diag=diag, **params)\n",
    "\n",
    "        #combine kernels\n",
    "        return matern_val * category_val\n",
    "    \n",
    "class CustomGPModel(gpytorch.models.ExactGP):\n",
    "    def __init__ (self, train_x, train_y, likelihood):\n",
    "        super().__init__(train_x, train_y, likelihood)\n",
    "        self.mean_module = gpytorch.means.ConstantMean()\n",
    "        self.covar_module = CombinedKernel()\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best continuous: [0.6], Best categorical: [1]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF, ConstantKernel as C\n",
    "\n",
    "class SimpleCoCaBO:\n",
    "    def __init__(self, continuous_dim, categorical_dim, kernel=None, noise_var=1e-5):\n",
    "        # Initialize the model with dimensions of continuous and categorical variables\n",
    "        self.continuous_dim = continuous_dim\n",
    "        self.categorical_dim = categorical_dim\n",
    "        \n",
    "        # Define the kernel for the Gaussian Process (RBF + constant kernel)\n",
    "        self.kernel = kernel if kernel else C(1.0, (1e-4, 1e1)) * RBF(1.0, (1e-4, 1e1))\n",
    "        \n",
    "        # Initialize the Gaussian Process Regressor\n",
    "        self.gpr = GaussianProcessRegressor(kernel=self.kernel, alpha=noise_var)\n",
    "\n",
    "        # Storage for past data\n",
    "        self.X = []  # Stores continuous + categorical variables\n",
    "        self.y = []  # Stores corresponding objective function values\n",
    "\n",
    "    def fit(self, X_cont, X_cat, y):\n",
    "        \"\"\"Fit the Gaussian Process model on both continuous and categorical data.\"\"\"\n",
    "        # Combine continuous and categorical data\n",
    "        X_combined = np.hstack((X_cont, X_cat))\n",
    "        \n",
    "        # Fit the Gaussian Process Regressor model\n",
    "        self.gpr.fit(X_combined, y)\n",
    "        \n",
    "        # Store the data for future optimization\n",
    "        self.X.extend(X_combined)\n",
    "        self.y.extend(y)\n",
    "\n",
    "    def predict(self, X_cont, X_cat):\n",
    "        \"\"\"Predict mean and variance for new points.\"\"\"\n",
    "        X_combined = np.hstack((X_cont, X_cat))\n",
    "        mean, std = self.gpr.predict(X_combined, return_std=True)\n",
    "        return mean, std\n",
    "\n",
    "    def ucb(self, X_cont, X_cat, kappa=2.0):\n",
    "        \"\"\"Upper Confidence Bound (UCB) acquisition function.\"\"\"\n",
    "        mean, std = self.predict(X_cont, X_cat)\n",
    "        ucb_values = mean + kappa * std\n",
    "        return ucb_values\n",
    "\n",
    "    def optimize(self, X_cont, X_cat, kappa=2.0):\n",
    "        \"\"\"Optimize the acquisition function (UCB).\"\"\"\n",
    "        ucb_values = self.ucb(X_cont, X_cat, kappa)\n",
    "        best_idx = np.argmax(ucb_values)  # Select the index with the highest UCB value\n",
    "        return X_cont[best_idx], X_cat[best_idx]\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Example continuous and categorical variables\n",
    "    X_cont = np.array([[0.5], [0.2], [0.7]])  # Example continuous variables\n",
    "    X_cat = np.array([[0], [1], [0]])  # Example categorical variables (just encoded as 0 or 1)\n",
    "    y = np.array([0.3, 0.7, 0.5])  # Objective values\n",
    "\n",
    "    # Instantiate the SimpleCoCaBO object\n",
    "    optimizer = SimpleCoCaBO(continuous_dim=1, categorical_dim=1)\n",
    "\n",
    "    # Fit the model to the data\n",
    "    optimizer.fit(X_cont, X_cat, y)\n",
    "\n",
    "    # Predict UCB values for new points\n",
    "    new_cont = np.array([[0.6], [0.3]])  # New continuous points to evaluate\n",
    "    new_cat = np.array([[1], [0]])  # New categorical points\n",
    "\n",
    "    best_cont, best_cat = optimizer.optimize(new_cont, new_cat)\n",
    "    print(f\"Best continuous: {best_cont}, Best categorical: {best_cat}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "testing"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "EnzymeKineticGPR-62lwjgN4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

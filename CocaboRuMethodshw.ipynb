{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "#==========================================\n",
    "# Title:  BaseBO.py\n",
    "# Author: Binxin Ru and Ahsan Alvi\n",
    "# Date:   20 August 2019\n",
    "# Link:   https://arxiv.org/abs/1906.08878\n",
    "#==========================================\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class BaseBO():\n",
    "    \"\"\"\n",
    "    Base class with common operations for BO with continuous and categorical\n",
    "    inputs\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, objfn, initN, bounds, C, rand_seed=108, debug=False,\n",
    "                 batch_size=1, **kwargs):\n",
    "        self.f = objfn  # function to optimise\n",
    "        self.bounds = bounds  # function bounds\n",
    "        self.batch_size = batch_size\n",
    "        self.C = C  # no of categories\n",
    "        self.initN = initN  # no: of initial points\n",
    "        self.nDim = len(self.bounds)  # dimension\n",
    "        self.rand_seed = rand_seed\n",
    "        self.debug = debug\n",
    "        self.saving_path = None\n",
    "        self.kwargs = kwargs\n",
    "        self.x_bounds = np.vstack([d['domain'] for d in self.bounds\n",
    "                                   if d['type'] == 'continuous'])\n",
    "\n",
    "    def initialise(self, seed):\n",
    "        \"\"\"Get NxN intial points\"\"\"\n",
    "        data = []\n",
    "        result = []\n",
    "\n",
    "        np.random.seed(seed)\n",
    "        random.seed(seed)\n",
    "\n",
    "        init_fname = self.saving_path + 'init_data_' + str(seed)\n",
    "\n",
    "        if os.path.exists(init_fname):\n",
    "            print(f\"Using existing init data for seed {seed}\")\n",
    "            with open(init_fname, 'rb') as init_data_filefile2:\n",
    "                init_data = pickle.load(init_data_filefile2)\n",
    "            Zinit = init_data['Z_init']\n",
    "            yinit = init_data['y_init']\n",
    "        else:\n",
    "            print(f\"Creating init data for seed {seed}\")\n",
    "            Xinit = self.generateInitialPoints(self.initN,\n",
    "                                               self.bounds[len(self.C):])\n",
    "            hinit = np.hstack(\n",
    "                [np.random.randint(0, C, self.initN)[:, None] for C in self.C])\n",
    "            Zinit = np.hstack((hinit, Xinit))\n",
    "            yinit = np.zeros([Zinit.shape[0], 1])\n",
    "\n",
    "            for j in range(self.initN):\n",
    "                ht_list = list(hinit[j])\n",
    "                yinit[j] = self.f(ht_list, Xinit[j])\n",
    "                # print(ht_list, Xinit[j], yinit[j])\n",
    "\n",
    "            init_data = {}\n",
    "            init_data['Z_init'] = Zinit\n",
    "            init_data['y_init'] = yinit\n",
    "\n",
    "            with open(init_fname, 'wb') as init_data_file:\n",
    "                pickle.dump(init_data, init_data_file)\n",
    "\n",
    "        data.append(Zinit)\n",
    "        result.append(yinit)\n",
    "        return data, result\n",
    "\n",
    "    def generateInitialPoints(self, initN, bounds):\n",
    "        nDim = len(bounds)\n",
    "        Xinit = np.zeros((initN, len(bounds)))\n",
    "        for i in range(initN):\n",
    "            Xinit[i, :] = np.array(\n",
    "                [np.random.uniform(bounds[b]['domain'][0],\n",
    "                                   bounds[b]['domain'][1], 1)[0]\n",
    "                 for b in range(nDim)])\n",
    "        return Xinit\n",
    "\n",
    "    def my_func(self, Z):\n",
    "        Z = np.atleast_2d(Z)\n",
    "        if len(Z) == 1:\n",
    "            X = Z[0, len(self.C):]\n",
    "            ht_list = list(Z[0, :len(self.C)])\n",
    "            return self.f(ht_list, X)\n",
    "        else:\n",
    "            f_vals = np.zeros(len(Z))\n",
    "            for ii in range(len(Z)):\n",
    "                X = Z[ii, len(self.C):]\n",
    "                ht_list = list(Z[ii, :len(self.C)].astype(int))\n",
    "                f_vals[ii] = self.f(ht_list, X)\n",
    "            return f_vals\n",
    "\n",
    "    def save_progress_to_disk(self, *args):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def runTrials(self, trials, budget, saving_path):\n",
    "        raise NotImplementedError\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "#==========================================\n",
    "# Title:  BatchCoCaBO.py\n",
    "# Author: Binxin Ru and Ahsan Alvi\n",
    "# Date:   20 August 2019\n",
    "# Link:   https://arxiv.org/abs/1906.08878\n",
    "#==========================================\n",
    "\n",
    "import math\n",
    "\n",
    "import GPy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "from utils.bayesopt.batch_bo import BatchBOHeuristic\n",
    "from utils.bayesopt.executor import JobExecutorInSeriesBlocking\n",
    "from utils.bayesopt.util import add_hallucinations_to_x_and_y\n",
    "from methods.CoCaBO_Base import CoCaBO_Base\n",
    "from utils.ml_utils.models import GP\n",
    "from utils.ml_utils.models.additive_gp import MixtureViaSumAndProduct, \\\n",
    "    CategoryOverlapKernel, GPWithSomeFixedDimsAtStart\n",
    "\n",
    "\n",
    "''' Batch CoCaBO algorithm '''\n",
    "class BatchCoCaBO(CoCaBO_Base):\n",
    "\n",
    "    def __init__(self, objfn, initN, bounds, acq_type, C, **kwargs):\n",
    "\n",
    "        super(BatchCoCaBO, self).__init__(objfn, initN, bounds, acq_type, C,\n",
    "                                          **kwargs)\n",
    "        self.best_val_list = []\n",
    "        self.C_list = self.C\n",
    "        self.name = 'BCoCaBO'\n",
    "\n",
    "    def runOptim(self, budget, seed, initData=None,\n",
    "                 initResult=None, ):\n",
    "\n",
    "        if (initData and initResult):\n",
    "            self.data = initData[:]\n",
    "            self.result = initResult[:]\n",
    "        else:\n",
    "            self.data, self.result = self.initialise(seed)\n",
    "\n",
    "        bestUpperBoundEstimate = 2 * budget / 3\n",
    "\n",
    "        gamma_list = [np.sqrt(C * math.log(C / self.batch_size) / (\n",
    "                (math.e - 1) * self.batch_size * bestUpperBoundEstimate))\n",
    "                      for C in self.C_list]\n",
    "        gamma_list = [g if not np.isnan(g) else 1 for g in gamma_list]\n",
    "\n",
    "        Wc_list_init = [np.ones(C) for C in self.C_list]\n",
    "        Wc_list = Wc_list_init\n",
    "        nDim = len(self.bounds)\n",
    "\n",
    "        result_list = []\n",
    "        starting_best = np.max(-1 * self.result[0])\n",
    "        result_list.append([-1, None, None, starting_best, None])\n",
    "\n",
    "        continuous_dims = list(range(len(self.C_list), nDim))\n",
    "        categorical_dims = list(range(len(self.C_list)))\n",
    "\n",
    "        for t in tqdm(range(budget)):\n",
    "            self.iteration = t\n",
    "            ht_batch_list, probabilityDistribution_list, S0 = self.compute_prob_dist_and_draw_hts(\n",
    "                Wc_list, gamma_list, self.batch_size)\n",
    "\n",
    "            ht_batch_list = ht_batch_list.astype(int)\n",
    "\n",
    "            # Obtain the reward for multi-armed bandit: B x len(self.C_list)\n",
    "            Gt_ht_list = self.RewardperCategoryviaBO(self.f, ht_batch_list,\n",
    "                                                     categorical_dims,\n",
    "                                                     continuous_dims)\n",
    "\n",
    "            # Update the reward and the weight\n",
    "            Wc_list = self.update_weights_for_all_cat_var(Gt_ht_list,\n",
    "                                                          ht_batch_list,\n",
    "                                                          Wc_list, gamma_list,\n",
    "                                                          probabilityDistribution_list,\n",
    "                                                          self.batch_size,\n",
    "                                                          S0=S0)\n",
    "\n",
    "            # Get the best value till now\n",
    "            besty, li, vi = self.getBestVal2(self.result)\n",
    "\n",
    "            # Store the results of this iteration\n",
    "            result_list.append(\n",
    "                [t, ht_batch_list, Gt_ht_list, besty, self.mix_used,\n",
    "                 self.model_hp])\n",
    "            self.ht_recommedations.append(ht_batch_list)\n",
    "\n",
    "        df = pd.DataFrame(result_list,\n",
    "                          columns=[\"iter\", \"ht\", \"Reward\", \"best_value\",\n",
    "                                   \"mix_val\", \"model_hp\"])\n",
    "        bestx = self.data[li][vi]\n",
    "        self.best_val_list.append(\n",
    "            [self.batch_size, self.trial_num, li, besty, bestx])\n",
    "        return df\n",
    "\n",
    "    # =============================================================================\n",
    "    #   Function returns the reward for multi-armed bandit\n",
    "    # =============================================================================\n",
    "    def RewardperCategoryviaBO(self, objfn, ht_next_batch_list,\n",
    "                               categorical_dims,\n",
    "                               continuous_dims):\n",
    "\n",
    "        #  Get observation data\n",
    "        Zt = self.data[0]\n",
    "        yt = self.result[0]\n",
    "\n",
    "        my_kernel, hp_bounds = self.get_kernel(categorical_dims,\n",
    "                                               continuous_dims)\n",
    "\n",
    "        gp_opt_params = {'method': 'multigrad',\n",
    "                         'num_restarts': 5,\n",
    "                         'restart_bounds': hp_bounds,\n",
    "                         'hp_bounds': hp_bounds,\n",
    "                         'verbose': False}\n",
    "\n",
    "        gp_kwargs = {'y_norm': 'meanstd',\n",
    "                     'opt_params': gp_opt_params}\n",
    "        gp_args = (Zt, yt, my_kernel)\n",
    "\n",
    "        gp = GP(*gp_args, **gp_kwargs)\n",
    "\n",
    "        opt_flag, gp = self.set_model_params_and_opt_flag(gp)\n",
    "        if opt_flag:\n",
    "            # print(\"\\noptimising!\\n\")\n",
    "            gp.optimize()\n",
    "        self.model_hp = gp.param_array\n",
    "\n",
    "        acq_dict = {'type': 'subspace'}\n",
    "\n",
    "        acq_opt_params = {'method': 'samplegrad',\n",
    "                          'num_local': 5,\n",
    "                          'num_samples': 5000,\n",
    "                          'num_chunks': 10,\n",
    "                          'verbose': False}\n",
    "\n",
    "        ymin_opt_params = {'method': 'standard'}\n",
    "\n",
    "        # Find the unique combinations in h and their frequency\n",
    "        h_unique, h_counts = np.unique(ht_next_batch_list,\n",
    "                                       return_counts=True, axis=0)\n",
    "\n",
    "        # Create the batch\n",
    "        z_batch_list = []\n",
    "        for idx, curr_h in enumerate(h_unique):\n",
    "            # Perform batch BO with a single fixed h\n",
    "            gp_for_bo = GPWithSomeFixedDimsAtStart(*gp_args,\n",
    "                                                   fixed_dim_vals=curr_h,\n",
    "                                                   **gp_kwargs)\n",
    "            gp_for_bo.param_array = gp.param_array\n",
    "\n",
    "            curr_batch_size = h_counts[idx]\n",
    "            interface = JobExecutorInSeriesBlocking(curr_batch_size)\n",
    "\n",
    "            # Adding repulsion effect to already-selected locations\n",
    "            if len(z_batch_list) > 0:\n",
    "                self.surrogate = gp_for_bo\n",
    "                self.async_infill_strategy = 'kriging_believer'  # hack\n",
    "                surrogate_x_with_fake, surrogate_y_with_fake = \\\n",
    "                    add_hallucinations_to_x_and_y(\n",
    "                        self, gp_for_bo.X, gp_for_bo.Y_raw,\n",
    "                        np.vstack(z_batch_list))\n",
    "                gp_for_bo.set_XY(X=surrogate_x_with_fake,\n",
    "                                 Y=surrogate_y_with_fake)\n",
    "\n",
    "            bo = BatchBOHeuristic(objfn, gp_for_bo, self.x_bounds,\n",
    "                                  async_infill_strategy='kriging_believer',\n",
    "                                  offset_acq=True,\n",
    "                                  async_interface=interface,\n",
    "                                  batch_size=curr_batch_size,\n",
    "                                  acq_dict=acq_dict,\n",
    "                                  y_min_opt_params=ymin_opt_params,\n",
    "                                  acq_opt_params=acq_opt_params,\n",
    "                                  optimise_surrogate_model=False)\n",
    "\n",
    "            x_batch_for_curr_h, _ = bo.get_next()\n",
    "\n",
    "            z_batch_for_curr_h = np.hstack((\n",
    "                np.vstack([curr_h] * curr_batch_size),\n",
    "                np.vstack(x_batch_for_curr_h)\n",
    "            ))\n",
    "            z_batch_list.append(z_batch_for_curr_h)\n",
    "\n",
    "        z_batch_next = np.vstack(z_batch_list)\n",
    "\n",
    "        #  Evaluate objective function at\n",
    "        y_batch_next = np.zeros((self.batch_size, 1))\n",
    "        for b in range(self.batch_size):\n",
    "            x_next = z_batch_next[b, continuous_dims]\n",
    "            ht_next_list = z_batch_next[b, categorical_dims]\n",
    "            try:\n",
    "                y_next = objfn(ht_next_list, x_next)\n",
    "            except:\n",
    "                print('stop')\n",
    "\n",
    "            y_batch_next[b] = y_next\n",
    "\n",
    "        # Append recommeded data\n",
    "        self.mix_used = gp.kern.mix[0]\n",
    "        self.data[0] = np.row_stack((self.data[0], z_batch_next))\n",
    "        self.result[0] = np.row_stack((self.result[0], y_batch_next))\n",
    "\n",
    "        # Obtain the reward for each categorical variable: B x len(self.C_list)\n",
    "        ht_batch_list_rewards = self.compute_reward_for_all_cat_variable(\n",
    "            ht_next_batch_list, self.batch_size)\n",
    "\n",
    "        bestval_ht = np.max(self.result[0] * -1)\n",
    "        # print(f'arm pulled={ht_next_batch_list[:]} ; '\n",
    "        #       f'\\n rewards = {ht_batch_list_rewards[:]}; '\n",
    "        #       f'y_best = {bestval_ht}; mix={self.mix_used}')\n",
    "        print(f'arm pulled={ht_next_batch_list[:]} ; '\n",
    "              f'y_best = {bestval_ht}; mix={self.mix_used}')\n",
    "\n",
    "        return ht_batch_list_rewards\n",
    "\n",
    "    def get_kernel(self, categorical_dims, continuous_dims):\n",
    "        # Create surrogate model\n",
    "        if self.ARD:\n",
    "            hp_bounds = np.array([\n",
    "                *[[1e-4, 3]] * len(continuous_dims),  # cont lengthscale\n",
    "                [1e-6, 1],  # likelihood variance\n",
    "            ])\n",
    "        else:\n",
    "            hp_bounds = np.array([\n",
    "                [1e-4, 3],  # cont lengthscale\n",
    "                [1e-6, 1],  # likelihood variance\n",
    "            ])\n",
    "        fix_mix_in_this_iter, mix_value, hp_bounds = self.get_mix(hp_bounds)\n",
    "        k_cat = CategoryOverlapKernel(len(categorical_dims),\n",
    "                                      active_dims=categorical_dims)  # cat\n",
    "        k_cont = GPy.kern.Matern52(len(continuous_dims),\n",
    "                                   lengthscale=self.default_cont_lengthscale,\n",
    "                                   active_dims=continuous_dims,\n",
    "                                   ARD=self.ARD)  # cont\n",
    "        my_kernel = MixtureViaSumAndProduct(\n",
    "            len(categorical_dims) + len(continuous_dims),\n",
    "            k_cat, k_cont, mix=mix_value, fix_inner_variances=True,\n",
    "            fix_mix=fix_mix_in_this_iter)\n",
    "        return my_kernel, hp_bounds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "#==========================================\n",
    "# Title:  CoCaBO_Base.py\n",
    "# Author: Binxin Ru and Ahsan Alvi\n",
    "# Date:   20 August 2019\n",
    "# Link:   https://arxiv.org/abs/1906.08878\n",
    "#==========================================\n",
    "\n",
    "import collections\n",
    "import pickle\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "from methods.BaseBO import BaseBO\n",
    "from utils.DepRound import DepRound\n",
    "from utils.probability import distr, draw\n",
    "\n",
    "\n",
    "class CoCaBO_Base(BaseBO):\n",
    "\n",
    "    def __init__(self, objfn, initN, bounds, acq_type, C,\n",
    "                 kernel_mix=0.5, mix_lr=10,\n",
    "                 model_update_interval=10,\n",
    "                 ard=False, **kwargs):\n",
    "        super().__init__(objfn, initN, bounds, C, **kwargs)\n",
    "        self.acq_type = acq_type\n",
    "\n",
    "        # Store the ht recommendations for each iteration\n",
    "        self.ht_recommedations = []\n",
    "        self.ht_hist_batch = []\n",
    "\n",
    "        # Store the name of the algorithm\n",
    "        self.policy = None\n",
    "\n",
    "        self.X = []\n",
    "        self.Y = []\n",
    "\n",
    "        # To check the best vals\n",
    "        self.gp_bestvals = []\n",
    "\n",
    "        self.ARD = ard\n",
    "\n",
    "        # Keeping track of current iteration helps control mix learning\n",
    "        self.iteration = None\n",
    "\n",
    "        self.model_hp = None\n",
    "        self.default_cont_lengthscale = 0.2\n",
    "\n",
    "        self.mix = kernel_mix\n",
    "        if ((model_update_interval % mix_lr == 0) or\n",
    "                (mix_lr % model_update_interval == 0)):\n",
    "            self.mix_learn_rate = mix_lr\n",
    "            self.model_update_interval = model_update_interval\n",
    "        else:\n",
    "            self.mix_learn_rate = min(mix_lr, model_update_interval)\n",
    "            self.model_update_interval = min(mix_lr, model_update_interval)\n",
    "        self.mix_used = 0.5\n",
    "\n",
    "        self.name = None\n",
    "\n",
    "    def estimate_alpha(self, batch_size, gamma, Wc, C):\n",
    "\n",
    "        def single_evaluation(alpha):\n",
    "            denominator = sum([alpha if val > alpha else val for idx, val in enumerate(Wc)])\n",
    "            rightside = (1 / batch_size - gamma / C) / (1 - gamma)\n",
    "            output = np.abs(alpha / denominator - rightside)\n",
    "\n",
    "            return output\n",
    "\n",
    "        x_tries = np.random.uniform(0, np.max(Wc), size=(100, 1))\n",
    "        y_tries = [single_evaluation(val) for val in x_tries]\n",
    "        # find x optimal for init\n",
    "        # print(f'ytry_len={len(y_tries)}')\n",
    "        idx_min = np.argmin(y_tries)\n",
    "        x_init_min = x_tries[idx_min]\n",
    "\n",
    "        res = minimize(single_evaluation, x_init_min, method='BFGS', options={'gtol': 1e-6, 'disp': False})\n",
    "        if isinstance(res, float):\n",
    "            return res\n",
    "        else:\n",
    "            return res.x\n",
    "\n",
    "    def runTrials(self, trials, budget, saving_path):\n",
    "        # Initialize mean_bestvals, stderr, hist\n",
    "        best_vals = []\n",
    "        mix_values = []\n",
    "        debug_values = []\n",
    "        n_working = trials\n",
    "        self.saving_path = saving_path\n",
    "\n",
    "        for i in range(trials):\n",
    "            print(\"Running trial: \", i)\n",
    "            self.trial_num = i\n",
    "            np.random.seed(i)\n",
    "            random.seed(i)\n",
    "\n",
    "            df = self.runOptim(budget=budget, seed=i)\n",
    "            best_vals.append(df['best_value'])\n",
    "            mix_values.append(df['mix_val'])\n",
    "            self.save_progress_to_disk(best_vals, debug_values, mix_values,\n",
    "                                       saving_path, df)\n",
    "\n",
    "        # Runoptim updates the ht_recommendation histogram\n",
    "        self.best_vals = best_vals\n",
    "        ht_hist = collections.Counter(np.array(self.ht_recommedations).ravel())\n",
    "        self.ht_recommedations = []\n",
    "        self.mean_best_vals = np.mean(best_vals, axis=0)\n",
    "        self.err_best_vals = np.std(best_vals, axis=0) / np.sqrt(n_working)\n",
    "\n",
    "        # For debugging\n",
    "        self.gp_bestvals = best_vals\n",
    "        self.ht_hist = ht_hist\n",
    "        self.n_working = n_working\n",
    "        return self.mean_best_vals, self.err_best_vals, ht_hist\n",
    "\n",
    "    def save_progress_to_disk(self, best_vals, debug_values, mix_values,\n",
    "                              saving_path, df):\n",
    "        results_file_name = saving_path + self.name + \\\n",
    "                            f'_{self.batch_size}' + \\\n",
    "                            '_best_vals_' + \\\n",
    "                            self.acq_type + \\\n",
    "                            '_ARD_' + str(self.ARD) + '_mix_' + \\\n",
    "                            str(self.mix)\n",
    "\n",
    "        with open(results_file_name, 'wb') as file:\n",
    "            pickle.dump(best_vals, file)\n",
    "        if self.mix > 1 or self.mix < 0:\n",
    "            mix_file_name = saving_path + self.name + \\\n",
    "                            f'_{self.batch_size}_' + \\\n",
    "                            self.acq_type + \\\n",
    "                            '_ARD_' + str(self.ARD) + '_mix_' + \\\n",
    "                            str(self.mix) + '_mix_values'\n",
    "            with open(mix_file_name, 'wb') as file2:\n",
    "                pickle.dump(mix_values, file2)\n",
    "        if self.debug:\n",
    "            debug_file_name = saving_path + self.name + \\\n",
    "                              f'_{self.batch_size}_' + \\\n",
    "                              self.acq_type + \\\n",
    "                              '_ARD_' + str(self.ARD) + '_mix_' + \\\n",
    "                              str(self.mix) + '_debug'\n",
    "            with open(debug_file_name, 'wb') as file2:\n",
    "                pickle.dump(debug_values, file2)\n",
    "\n",
    "        df.to_pickle(f\"{results_file_name}_df_s{self.trial_num}\")\n",
    "\n",
    "    def compute_reward_for_all_cat_variable(self, ht_next_batch_list, batch_size):\n",
    "        # Obtain the reward for each categorical variable: B x len(self.C_list)\n",
    "        ht_batch_list_rewards = np.zeros((batch_size, len(self.C_list)))\n",
    "        for b in range(batch_size):\n",
    "            ht_next_list = ht_next_batch_list[b, :]\n",
    "\n",
    "            for i in range(len(ht_next_list)):\n",
    "                idices = np.where(self.data[0][:, i] == ht_next_list[i])\n",
    "                ht_result = self.result[0][idices]\n",
    "                ht_reward = np.max(ht_result * -1)\n",
    "                ht_batch_list_rewards[b, i] = ht_reward\n",
    "        return ht_batch_list_rewards\n",
    "\n",
    "    def update_weights_for_all_cat_var(self, Gt_ht_list, ht_batch_list, Wc_list, gamma_list,\n",
    "                                       probabilityDistribution_list, batch_size, S0=None):\n",
    "        for j in range(len(self.C_list)):\n",
    "            Wc = Wc_list[j]\n",
    "            C = self.C_list[j]\n",
    "            gamma = gamma_list[j]\n",
    "            probabilityDistribution = probabilityDistribution_list[j]\n",
    "            # print(f'cat_var={j}, prob={probabilityDistribution}')\n",
    "\n",
    "            if batch_size > 1:\n",
    "                ht_batch_list = ht_batch_list.astype(int)\n",
    "                Gt_ht = Gt_ht_list[:, j]\n",
    "                mybatch_ht = ht_batch_list[:, j]  # 1xB\n",
    "                for ii, ht in enumerate(mybatch_ht):\n",
    "                    Gt_ht_b = Gt_ht[ii]\n",
    "                    estimatedReward = 1.0 * Gt_ht_b / probabilityDistribution[ht]\n",
    "                    if ht not in S0:\n",
    "                        Wc[ht] *= np.exp(batch_size * estimatedReward * gamma / C)\n",
    "            else:\n",
    "                Gt_ht = Gt_ht_list[j]\n",
    "                ht = ht_batch_list[j]  # 1xB\n",
    "                estimatedReward = 1.0 * Gt_ht / probabilityDistribution[ht]\n",
    "                Wc[ht] *= np.exp(estimatedReward * gamma / C)\n",
    "\n",
    "        return Wc_list\n",
    "\n",
    "    def compute_prob_dist_and_draw_hts(self, Wc_list, gamma_list, batch_size):\n",
    "\n",
    "        if batch_size > 1:\n",
    "            ht_batch_list = np.zeros((batch_size, len(self.C_list)))\n",
    "            probabilityDistribution_list = []\n",
    "\n",
    "            for j in range(len(self.C_list)):\n",
    "                Wc = Wc_list[j]\n",
    "                gamma = gamma_list[j]\n",
    "                C = self.C_list[j]\n",
    "                # perform some truncation here\n",
    "                maxW = np.max(Wc)\n",
    "                temp = np.sum(Wc) * (1.0 / batch_size - gamma / C) / (1 - gamma)\n",
    "                if gamma < 1 and maxW >= temp:\n",
    "                    # find a threshold alpha\n",
    "                    alpha = self.estimate_alpha(batch_size, gamma, Wc, C)\n",
    "                    S0 = [idx for idx, val in enumerate(Wc) if val > alpha]\n",
    "                else:\n",
    "                    S0 = []\n",
    "                # Compute the probability for each category\n",
    "                probabilityDistribution = distr(Wc, gamma)\n",
    "\n",
    "                # draw a batch here\n",
    "                if batch_size < C:\n",
    "                    mybatch_ht = DepRound(probabilityDistribution, k=batch_size)\n",
    "                else:\n",
    "                    mybatch_ht = np.random.choice(len(probabilityDistribution), batch_size, p=probabilityDistribution)\n",
    "\n",
    "                # ht_batch_list size: len(self.C_list) x B\n",
    "                ht_batch_list[:, j] = mybatch_ht[:]\n",
    "\n",
    "                # ht_batch_list.append(mybatch_ht)\n",
    "                probabilityDistribution_list.append(probabilityDistribution)\n",
    "\n",
    "            return ht_batch_list, probabilityDistribution_list, S0\n",
    "\n",
    "        else:\n",
    "            ht_list = []\n",
    "            probabilityDistribution_list = []\n",
    "            for j in range(len(self.C_list)):\n",
    "                Wc = Wc_list[j]\n",
    "                gamma = gamma_list[j]\n",
    "                # Compute the probability for each category\n",
    "                probabilityDistribution = distr(Wc, gamma)\n",
    "                # Choose a categorical variable at random\n",
    "                ht = draw(probabilityDistribution)\n",
    "                ht_list.append(ht)\n",
    "                probabilityDistribution_list.append(probabilityDistribution)\n",
    "\n",
    "            return ht_list, probabilityDistribution_list\n",
    "\n",
    "    def compute_weights_for_init_data(self, Wc_list_init, gamma_list, batch_size):\n",
    "        ht_next_batch_list = self.data[0][:, :len(self.C)]\n",
    "        _, probabilityDistribution_list, S0 = self.compute_prob_dist_and_draw_hts(Wc_list_init, gamma_list,\n",
    "                                                                                  ht_next_batch_list.shape[0])\n",
    "        Gt_ht_list = self.compute_reward_for_all_cat_variable(ht_next_batch_list, ht_next_batch_list.shape[0])\n",
    "        New_Wc_list = self.update_weights_for_all_cat_var(Gt_ht_list, ht_next_batch_list, Wc_list_init, gamma_list,\n",
    "                                                          probabilityDistribution_list, ht_next_batch_list.shape[0],\n",
    "                                                          S0=S0)\n",
    "\n",
    "        return New_Wc_list\n",
    "\n",
    "    def get_mix(self, hp_bounds):\n",
    "        fix_mix_in_this_iter = True\n",
    "        if (self.mix >= 0) and (self.mix <= 1):  # mix param is fixed\n",
    "            mix_value = self.mix\n",
    "        elif ((self.iteration >= self.mix_learn_rate) and\n",
    "              (self.iteration % self.mix_learn_rate == 0)):\n",
    "            # learn mix\n",
    "            hp_bounds = np.vstack(([1e-6, 1], hp_bounds))\n",
    "            fix_mix_in_this_iter = False\n",
    "            mix_value = 0.5\n",
    "        else:  # between learning iterations\n",
    "            mix_value = self.mix_used\n",
    "        return fix_mix_in_this_iter, mix_value, hp_bounds\n",
    "\n",
    "    # ========================================\n",
    "    #     Over-ride this!\n",
    "    # =============================================================================\n",
    "    def runOptim(self, budget, seed):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    # =============================================================================\n",
    "    # Get best value from nested list along with the index\n",
    "    # =============================================================================\n",
    "    def getBestVal2(self, my_list):\n",
    "        temp = [np.max(i * -1) for i in my_list]\n",
    "        indx1 = [np.argmax(i * -1) for i in my_list]\n",
    "        indx2 = np.argmax(temp)\n",
    "        val = np.max(temp)\n",
    "        list_indx = indx2\n",
    "        val_indx = indx1[indx2]\n",
    "        return val, list_indx, val_indx\n",
    "\n",
    "    def set_model_params_and_opt_flag(self, model):\n",
    "        \"\"\"\n",
    "        Returns opt_flag, model\n",
    "        \"\"\"\n",
    "        if ((self.iteration >= self.model_update_interval) and\n",
    "                (self.iteration % self.model_update_interval == 0)):\n",
    "            return True, model\n",
    "        else:\n",
    "            # No previous model_hp, so optimise\n",
    "            if self.model_hp is None:\n",
    "                self.model_hp = model.param_array\n",
    "            else:\n",
    "                # print(self.model_hp)\n",
    "                # print(model.param_array)\n",
    "                # previous iter learned mix, so remove mix before setting\n",
    "                if len(model.param_array) < len(self.model_hp):\n",
    "                    model.param_array = self.model_hp[1:]\n",
    "                else:\n",
    "                    model.param_array = self.model_hp\n",
    "\n",
    "            return False, model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "#==========================================\n",
    "# Title:  CoCaBO.py\n",
    "# Author: Binxin Ru and Ahsan Alvi\n",
    "# Date:   20 August 2019\n",
    "# Link:   https://arxiv.org/abs/1906.08878\n",
    "#==========================================\n",
    "\n",
    "import math\n",
    "\n",
    "import GPy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "from utils.bayesopt.acquisition import AcquisitionOnSubspace, EI, UCB\n",
    "from methods.CoCaBO_Base import CoCaBO_Base\n",
    "from utils.ml_utils.models import GP\n",
    "from utils.ml_utils.models.additive_gp import MixtureViaSumAndProduct, \\\n",
    "    CategoryOverlapKernel\n",
    "from utils.ml_utils.optimization import sample_then_minimize\n",
    "\n",
    "''' Sequential CoCaBO algorithm '''\n",
    "class CoCaBO(CoCaBO_Base):\n",
    "\n",
    "    def __init__(self, objfn, initN, bounds, acq_type, C, **kwargs):\n",
    "\n",
    "        super(CoCaBO, self).__init__(objfn, initN, bounds, acq_type, C, **kwargs)\n",
    "        self.best_val_list = []\n",
    "        self.C_list = self.C\n",
    "        self.name = 'CoCaBO'\n",
    "\n",
    "    def runOptim(self, budget, seed, batch_size=1, initData=None, initResult=None):\n",
    "\n",
    "        if (initData and initResult):\n",
    "            self.data = initData[:]\n",
    "            self.result = initResult[:]\n",
    "        else:\n",
    "            self.data, self.result = self.initialise(seed)\n",
    "\n",
    "        # Initialize wts and probs\n",
    "        b = batch_size\n",
    "        bestUpperBoundEstimate = 2 * budget / 3\n",
    "        gamma_list = [math.sqrt(C * math.log(C) /\n",
    "                                ((math.e - 1) * bestUpperBoundEstimate))\n",
    "                      for C in self.C_list]\n",
    "        Wc_list_init = [np.ones(C) for C in self.C_list]\n",
    "        Wc_list = Wc_list_init\n",
    "        nDim = len(self.bounds)\n",
    "\n",
    "        result_list = []\n",
    "        starting_best = np.max(-1 * self.result[0])\n",
    "        result_list.append([-1, None, None, starting_best, None])\n",
    "\n",
    "        continuous_dims = list(range(len(self.C_list), nDim))\n",
    "        categorical_dims = list(range(len(self.C_list)))\n",
    "\n",
    "        for t in tqdm(range(budget)):\n",
    "            self.iteration = t\n",
    "\n",
    "            # Compute the probability for each category and Choose categorical variables\n",
    "            ht_list, probabilityDistribution_list = \\\n",
    "                self.compute_prob_dist_and_draw_hts(Wc_list, gamma_list,\n",
    "                                                    batch_size)\n",
    "\n",
    "            # Get reward for multi-armed bandit\n",
    "            Gt_ht_list = self.RewardperCategoryviaBO(self.f, ht_list,\n",
    "                                                     categorical_dims,\n",
    "                                                     continuous_dims,\n",
    "                                                     self.bounds,\n",
    "                                                     self.acq_type, b)\n",
    "\n",
    "            # Update the reward and the weight\n",
    "            Wc_list = self.update_weights_for_all_cat_var(\n",
    "                Gt_ht_list, ht_list,\n",
    "                Wc_list, gamma_list,\n",
    "                probabilityDistribution_list,\n",
    "                batch_size)\n",
    "\n",
    "            # Get the best value till now\n",
    "            besty, li, vi = self.getBestVal2(self.result)\n",
    "\n",
    "            # Store the results of this iteration\n",
    "            result_list.append([t, ht_list, Gt_ht_list, besty, self.mix_used,\n",
    "                                self.model_hp])\n",
    "\n",
    "            self.ht_recommedations.append(ht_list)\n",
    "\n",
    "        df = pd.DataFrame(result_list, columns=[\"iter\", \"ht\", \"Reward\",\n",
    "                                                \"best_value\", \"mix_val\",\n",
    "                                                \"model_hp\"])\n",
    "        bestx = self.data[li][vi]\n",
    "        self.best_val_list.append([batch_size, self.trial_num, li, besty,\n",
    "                                   bestx])\n",
    "\n",
    "        return df\n",
    "\n",
    "    # =============================================================================\n",
    "    #   Function returns the reward for multi-armed bandit\n",
    "    # =============================================================================\n",
    "    def RewardperCategoryviaBO(self, objfn, ht_next_list, categorical_dims,\n",
    "                               continuous_dims, bounds, acq_type, b):\n",
    "\n",
    "        #  Get observation data\n",
    "        Zt = self.data[0]\n",
    "        yt = self.result[0]\n",
    "\n",
    "        my_kernel, hp_bounds = self.get_kernel(categorical_dims,\n",
    "                                               continuous_dims)\n",
    "\n",
    "        gp_opt_params = {'method': 'multigrad',\n",
    "                         'num_restarts': 5,\n",
    "                         'restart_bounds': hp_bounds,\n",
    "                         'hp_bounds': hp_bounds,\n",
    "                         'verbose': False}\n",
    "\n",
    "        gp = GP(Zt, yt, my_kernel, y_norm='meanstd',\n",
    "                opt_params=gp_opt_params)\n",
    "\n",
    "        opt_flag, gp = self.set_model_params_and_opt_flag(gp)\n",
    "        if opt_flag:\n",
    "            # print(\"\\noptimising!\\n\")\n",
    "            gp.optimize()\n",
    "        self.model_hp = gp.param_array\n",
    "\n",
    "\n",
    "        self.mix_used = gp.kern.mix[0]\n",
    "\n",
    "        x_bounds = np.array([d['domain'] for d in bounds\n",
    "                             if d['type'] == 'continuous'])\n",
    "        # create acq\n",
    "        if acq_type == 'EI':\n",
    "            acq = EI(gp, np.min(gp.Y_raw))\n",
    "        elif acq_type == 'LCB':\n",
    "            acq = UCB(gp, 2.0)\n",
    "\n",
    "        acq_sub = AcquisitionOnSubspace(acq, my_kernel.k2.active_dims,\n",
    "                                        ht_next_list)\n",
    "\n",
    "        def optimiser_func(x):\n",
    "            return -acq_sub.evaluate(np.atleast_2d(x))\n",
    "\n",
    "        res = sample_then_minimize(\n",
    "            optimiser_func,\n",
    "            x_bounds,\n",
    "            num_samples=5000,\n",
    "            num_chunks=10,\n",
    "            num_local=3,\n",
    "            minimize_options=None,\n",
    "            evaluate_sequentially=False)\n",
    "\n",
    "        x_next = res.x\n",
    "        z_next = np.hstack((ht_next_list, x_next))\n",
    "\n",
    "        #  Evaluate objective function at z_next = [x_next,  ht_next_list]\n",
    "        y_next = objfn(ht_next_list, x_next)\n",
    "\n",
    "        # Append recommeded data\n",
    "        self.data[0] = np.row_stack((self.data[0], z_next))\n",
    "        self.result[0] = np.row_stack((self.result[0], y_next))\n",
    "\n",
    "        # Obtain the reward for each categorical variable\n",
    "        ht_next_list_array = np.atleast_2d(ht_next_list)\n",
    "        ht_list_rewards = self.compute_reward_for_all_cat_variable(\n",
    "            ht_next_list_array, b)\n",
    "        ht_list_rewards = list(ht_list_rewards.flatten())\n",
    "\n",
    "        bestval_ht = np.max(self.result[0] * -1)\n",
    "        # print(f'arm pulled={ht_next_list[:]} ; rewards = {ht_list_rewards[:]};'\n",
    "        #       f' y_best = {bestval_ht}; mix={self.mix_used}')\n",
    "        print(f'arm pulled={ht_next_list[:]}; y_best = {bestval_ht}; mix={self.mix_used}')\n",
    "\n",
    "        return ht_list_rewards\n",
    "\n",
    "    def get_kernel(self, categorical_dims, continuous_dims):\n",
    "        # create surrogate\n",
    "        if self.ARD:\n",
    "            hp_bounds = np.array([\n",
    "                *[[1e-4, 3]] * len(continuous_dims),  # cont lengthscale\n",
    "                [1e-6, 1],  # likelihood variance\n",
    "            ])\n",
    "        else:\n",
    "            hp_bounds = np.array([\n",
    "                [1e-4, 3],  # cont lengthscale\n",
    "                [1e-6, 1],  # likelihood variance\n",
    "            ])\n",
    "        fix_mix_in_this_iter, mix_value, hp_bounds = self.get_mix(hp_bounds)\n",
    "        k_cat = CategoryOverlapKernel(len(categorical_dims),\n",
    "                                      active_dims=categorical_dims)  # cat\n",
    "        k_cont = GPy.kern.Matern52(len(continuous_dims),\n",
    "                                   lengthscale=self.default_cont_lengthscale,\n",
    "                                   active_dims=continuous_dims,\n",
    "                                   ARD=self.ARD)  # cont\n",
    "        my_kernel = MixtureViaSumAndProduct(\n",
    "            len(categorical_dims) + len(continuous_dims),\n",
    "            k_cat, k_cont, mix=mix_value, fix_inner_variances=True,\n",
    "            fix_mix=fix_mix_in_this_iter)\n",
    "        return my_kernel, hp_bounds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "#==========================================\n",
    "# Title:  syntheticFunctions.py\n",
    "# Author: Binxin Ru and Ahsan Alvi\n",
    "# Date:   20 August 2019\n",
    "# Link:   https://arxiv.org/abs/1906.08878\n",
    "#==========================================\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# =============================================================================\n",
    "# Rosenbrock Function (f_min = 0)\n",
    "# https://www.sfu.ca/~ssurjano/rosen.html\n",
    "# =============================================================================\n",
    "def myrosenbrock(X):\n",
    "    X = np.asarray(X)\n",
    "    X = X.reshape((-1, 2))\n",
    "    if len(X.shape) == 1:  # one observation\n",
    "        x1 = X[0]\n",
    "        x2 = X[1]\n",
    "    else:  # multiple observations\n",
    "        x1 = X[:, 0]\n",
    "        x2 = X[:, 1]\n",
    "    fx = 100 * (x2 - x1 ** 2) ** 2 + (x1 - 1) ** 2\n",
    "    return fx.reshape(-1, 1) / 300\n",
    "\n",
    "# =============================================================================\n",
    "#  Six-hump Camel Function (f_min = - 1.0316 )\n",
    "#  https://www.sfu.ca/~ssurjano/camel6.html       \n",
    "# =============================================================================\n",
    "def mysixhumpcamp(X):\n",
    "    X = np.asarray(X)\n",
    "    X = np.reshape(X, (-1, 2))\n",
    "    if len(X.shape) == 1:\n",
    "        x1 = X[0]\n",
    "        x2 = X[1]\n",
    "    else:\n",
    "        x1 = X[:, 0]\n",
    "        x2 = X[:, 1]\n",
    "    term1 = (4 - 2.1 * x1 ** 2 + (x1 ** 4) / 3) * x1 ** 2\n",
    "    term2 = x1 * x2\n",
    "    term3 = (-4 + 4 * x2 ** 2) * x2 ** 2\n",
    "    fval = term1 + term2 + term3\n",
    "    return fval.reshape(-1, 1) / 10\n",
    "\n",
    "# =============================================================================\n",
    "# Beale function (f_min = 0)\n",
    "# https://www.sfu.ca/~ssurjano/beale.html\n",
    "# =============================================================================\n",
    "def mybeale(X):\n",
    "    X = np.asarray(X) / 2\n",
    "    X = X.reshape((-1, 2))\n",
    "    if len(X.shape) == 1:\n",
    "        x1 = X[0] * 2\n",
    "        x2 = X[1] * 2\n",
    "    else:\n",
    "        x1 = X[:, 0] * 2\n",
    "        x2 = X[:, 1] * 2\n",
    "    fval = (1.5 - x1 + x1 * x2) ** 2 + (2.25 - x1 + x1 * x2 ** 2) ** 2 + (\n",
    "            2.625 - x1 + x1 * x2 ** 3) ** 2\n",
    "    return fval.reshape(-1, 1) / 50\n",
    "\n",
    "\n",
    "def func2C(ht_list, X):\n",
    "    # ht is a categorical index\n",
    "    # X is a continuous variable\n",
    "    X = X * 2\n",
    "\n",
    "    assert len(ht_list) == 2\n",
    "    ht1 = ht_list[0]\n",
    "    ht2 = ht_list[1]\n",
    "\n",
    "    if ht1 == 0:  # rosenbrock\n",
    "        f = myrosenbrock(X)\n",
    "    elif ht1 == 1:  # six hump\n",
    "        f = mysixhumpcamp(X)\n",
    "    elif ht1 == 2:  # beale\n",
    "        f = mybeale(X)\n",
    "\n",
    "    if ht2 == 0:  # rosenbrock\n",
    "        f = f + myrosenbrock(X)\n",
    "    elif ht2 == 1:  # six hump\n",
    "        f = f + mysixhumpcamp(X)\n",
    "    else:\n",
    "        f = f + mybeale(X)\n",
    "\n",
    "    y = f + 1e-6 * np.random.rand(f.shape[0], f.shape[1])\n",
    "    return y.astype(float)\n",
    "\n",
    "\n",
    "def func3C(ht_list, X):\n",
    "    # ht is a categorical index\n",
    "    # X is a continuous variable\n",
    "    X = np.atleast_2d(X)\n",
    "    assert len(ht_list) == 3\n",
    "    ht1 = ht_list[0]\n",
    "    ht2 = ht_list[1]\n",
    "    ht3 = ht_list[2]\n",
    "\n",
    "    X = X * 2\n",
    "    if ht1 == 0:  # rosenbrock\n",
    "        f = myrosenbrock(X)\n",
    "    elif ht1 == 1:  # six hump\n",
    "        f = mysixhumpcamp(X)\n",
    "    elif ht1 == 2:  # beale\n",
    "        f = mybeale(X)\n",
    "\n",
    "    if ht2 == 0:  # rosenbrock\n",
    "        f = f + myrosenbrock(X)\n",
    "    elif ht2 == 1:  # six hump\n",
    "        f = f + mysixhumpcamp(X)\n",
    "    else:\n",
    "        f = f + mybeale(X)\n",
    "\n",
    "    if ht3 == 0:  # rosenbrock\n",
    "        f = f + 5 * mysixhumpcamp(X)\n",
    "    elif ht3 == 1:  # six hump\n",
    "        f = f + 2 * myrosenbrock(X)\n",
    "    else:\n",
    "        f = f + ht3 * mybeale(X)\n",
    "\n",
    "    y = f + 1e-6 * np.random.rand(f.shape[0], f.shape[1])\n",
    "\n",
    "    return y.astype(float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got arguments: \n",
      "Namespace(func='/Users/s/Library/Jupyter/runtime/kernel-v3f138c4f094371e7d174d8c61457d2247b3a6d3d0.json', kernel_mix=0.0, max_itr=100, trials=20, batch=2)\n"
     ]
    },
    {
     "ename": "NotImplementedError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNotImplementedError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 93\u001b[39m\n\u001b[32m     90\u001b[39m n_trials = args.trials\n\u001b[32m     91\u001b[39m batch = args.batch\n\u001b[32m---> \u001b[39m\u001b[32m93\u001b[39m \u001b[43mCoCaBO_Exps\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj_func\u001b[49m\u001b[43m=\u001b[49m\u001b[43mobj_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbudget\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_itrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     94\u001b[39m \u001b[43m             \u001b[49m\u001b[43mtrials\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkernel_mix\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mkernel_mix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 50\u001b[39m, in \u001b[36mCoCaBO_Exps\u001b[39m\u001b[34m(obj_func, budget, initN, trials, kernel_mix, batch)\u001b[39m\n\u001b[32m     43\u001b[39m     bounds = [{\u001b[33m'\u001b[39m\u001b[33mname\u001b[39m\u001b[33m'\u001b[39m: \u001b[33m'\u001b[39m\u001b[33mh1\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mtype\u001b[39m\u001b[33m'\u001b[39m: \u001b[33m'\u001b[39m\u001b[33mcategorical\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mdomain\u001b[39m\u001b[33m'\u001b[39m: (\u001b[32m0\u001b[39m, \u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m)},\n\u001b[32m     44\u001b[39m         {\u001b[33m'\u001b[39m\u001b[33mname\u001b[39m\u001b[33m'\u001b[39m: \u001b[33m'\u001b[39m\u001b[33mh2\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mtype\u001b[39m\u001b[33m'\u001b[39m: \u001b[33m'\u001b[39m\u001b[33mcategorical\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mdomain\u001b[39m\u001b[33m'\u001b[39m: (\u001b[32m0\u001b[39m, \u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m, \u001b[32m3\u001b[39m, \u001b[32m4\u001b[39m)},\n\u001b[32m     45\u001b[39m         {\u001b[33m'\u001b[39m\u001b[33mname\u001b[39m\u001b[33m'\u001b[39m: \u001b[33m'\u001b[39m\u001b[33mh3\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mtype\u001b[39m\u001b[33m'\u001b[39m: \u001b[33m'\u001b[39m\u001b[33mcategorical\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mdomain\u001b[39m\u001b[33m'\u001b[39m: (\u001b[32m0\u001b[39m, \u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m, \u001b[32m3\u001b[39m)},\n\u001b[32m     46\u001b[39m         {\u001b[33m'\u001b[39m\u001b[33mname\u001b[39m\u001b[33m'\u001b[39m: \u001b[33m'\u001b[39m\u001b[33mx1\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mtype\u001b[39m\u001b[33m'\u001b[39m: \u001b[33m'\u001b[39m\u001b[33mcontinuous\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mdomain\u001b[39m\u001b[33m'\u001b[39m: (-\u001b[32m1\u001b[39m, \u001b[32m1\u001b[39m)},\n\u001b[32m     47\u001b[39m         {\u001b[33m'\u001b[39m\u001b[33mname\u001b[39m\u001b[33m'\u001b[39m: \u001b[33m'\u001b[39m\u001b[33mx2\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mtype\u001b[39m\u001b[33m'\u001b[39m: \u001b[33m'\u001b[39m\u001b[33mcontinuous\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mdomain\u001b[39m\u001b[33m'\u001b[39m: (-\u001b[32m1\u001b[39m, \u001b[32m1\u001b[39m)}]\n\u001b[32m     49\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m50\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m\n\u001b[32m     52\u001b[39m \u001b[38;5;66;03m# Run CoCaBO Algorithm\u001b[39;00m\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m batch == \u001b[32m1\u001b[39m:\n\u001b[32m     54\u001b[39m     \u001b[38;5;66;03m# sequential CoCaBO\u001b[39;00m\n",
      "\u001b[31mNotImplementedError\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "#==========================================\n",
    "# Title:  run_cocabo_exps.py\n",
    "# Author: Binxin Ru and Ahsan Alvi\n",
    "# Date:   20 August 2019\n",
    "# Link:   https://arxiv.org/abs/1906.08878\n",
    "#==========================================\n",
    "\n",
    "# =============================================================================\n",
    "#  CoCaBO Algorithms \n",
    "# =============================================================================\n",
    "import sys\n",
    "# sys.path.append('../bayesopt')\n",
    "# sys.path.append('../ml_utils')\n",
    "import argparse\n",
    "import os\n",
    "import testFunctions.syntheticFunctions\n",
    "from methods.CoCaBO import CoCaBO\n",
    "from methods.BatchCoCaBO import BatchCoCaBO\n",
    "\n",
    "\n",
    "def CoCaBO_Exps(obj_func, budget, initN=24 ,trials=40, kernel_mix = 0.5, batch=None):\n",
    "\n",
    "    # define saving path for saving the results\n",
    "    saving_path = f'data/syntheticFns/{obj_func}/'\n",
    "    if not os.path.exists(saving_path):\n",
    "        os.makedirs(saving_path)\n",
    "\n",
    "    # define the objective function\n",
    "    if obj_func == 'func2C':\n",
    "        f = testFunctions.syntheticFunctions.func2C\n",
    "        categories = [3, 5]\n",
    "\n",
    "        bounds = [{'name': 'h1', 'type': 'categorical', 'domain': (0, 1, 2)},\n",
    "            {'name': 'h2', 'type': 'categorical', 'domain': (0, 1, 2, 3, 4)},\n",
    "            {'name': 'x1', 'type': 'continuous', 'domain': (-1, 1)},\n",
    "            {'name': 'x2', 'type': 'continuous', 'domain': (-1, 1)}]\n",
    "\n",
    "    elif obj_func == 'func3C':\n",
    "        f = testFunctions.syntheticFunctions.func3C\n",
    "        categories = [3, 5, 4]\n",
    "\n",
    "        bounds = [{'name': 'h1', 'type': 'categorical', 'domain': (0, 1, 2)},\n",
    "            {'name': 'h2', 'type': 'categorical', 'domain': (0, 1, 2, 3, 4)},\n",
    "            {'name': 'h3', 'type': 'categorical', 'domain': (0, 1, 2, 3)},\n",
    "            {'name': 'x1', 'type': 'continuous', 'domain': (-1, 1)},\n",
    "            {'name': 'x2', 'type': 'continuous', 'domain': (-1, 1)}]\n",
    "\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    # Run CoCaBO Algorithm\n",
    "    if batch == 1:\n",
    "        # sequential CoCaBO\n",
    "        mabbo = CoCaBO(objfn=f, initN=initN, bounds=bounds,\n",
    "                       acq_type='LCB', C=categories,\n",
    "                       kernel_mix = kernel_mix)\n",
    "\n",
    "    else:\n",
    "        # batch CoCaBO\n",
    "        mabbo = BatchCoCaBO(objfn=f, initN=initN, bounds=bounds,\n",
    "                            acq_type='LCB', C=categories,\n",
    "                            kernel_mix=kernel_mix,\n",
    "                            batch_size=batch)\n",
    "    mabbo.runTrials(trials, budget, saving_path)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    parser = argparse.ArgumentParser(description=\"Run BayesOpt Experiments\")\n",
    "    parser.add_argument('-f', '--func', help='Objective function',\n",
    "                        default='func2C', type=str)\n",
    "    parser.add_argument('-mix', '--kernel_mix',\n",
    "                        help='Mixture weight for production and summation kernel. Default = 0.0', default=0.0,\n",
    "                        type=float)\n",
    "    parser.add_argument('-n', '--max_itr', help='Max Optimisation iterations. Default = 100',\n",
    "                        default=100, type=int)\n",
    "    parser.add_argument('-tl', '--trials', help='Number of random trials. Default = 20',\n",
    "                        default=20, type=int)\n",
    "    parser.add_argument('-b', '--batch', help='Batch size (>1 for batch CoCaBO and =1 for sequential CoCaBO). Default = 1',\n",
    "                        default=2, type=int)\n",
    "\n",
    "    args = parser.parse_args()\n",
    "    print(f\"Got arguments: \\n{args}\")\n",
    "    obj_func = args.func\n",
    "    kernel_mix = args.kernel_mix\n",
    "    n_itrs = args.max_itr\n",
    "    n_trials = args.trials\n",
    "    batch = args.batch\n",
    "\n",
    "    CoCaBO_Exps(obj_func=obj_func, budget=n_itrs,\n",
    "                 trials=n_trials, kernel_mix = kernel_mix, batch=batch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (venv)",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
